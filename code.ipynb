{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724699c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        30\n",
      "           1       0.86      0.89      0.87        81\n",
      "           2       0.87      0.80      0.84        41\n",
      "           3       0.89      0.89      0.89        27\n",
      "           4       0.90      0.95      0.93        20\n",
      "           5       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.88       208\n",
      "   macro avg       0.90      0.88      0.89       208\n",
      "weighted avg       0.88      0.88      0.87       208\n",
      "\n",
      "Accuracy: 0.875\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77        30\n",
      "           1       0.80      0.83      0.81        81\n",
      "           2       0.84      0.63      0.72        41\n",
      "           3       0.69      0.74      0.71        27\n",
      "           4       0.88      0.70      0.78        20\n",
      "           5       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.78       208\n",
      "   macro avg       0.81      0.78      0.79       208\n",
      "weighted avg       0.79      0.78      0.78       208\n",
      "\n",
      "Accuracy: 0.7788461538461539\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92        30\n",
      "           1       0.89      0.91      0.90        81\n",
      "           2       0.84      0.78      0.81        41\n",
      "           3       0.81      0.81      0.81        27\n",
      "           4       0.95      0.95      0.95        20\n",
      "           5       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.88       208\n",
      "   macro avg       0.90      0.90      0.90       208\n",
      "weighted avg       0.88      0.88      0.88       208\n",
      "\n",
      "Accuracy: 0.8846153846153846\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92        30\n",
      "           1       0.89      0.91      0.90        81\n",
      "           2       0.84      0.78      0.81        41\n",
      "           3       0.81      0.81      0.81        27\n",
      "           4       0.95      0.95      0.95        20\n",
      "           5       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.88       208\n",
      "   macro avg       0.90      0.90      0.90       208\n",
      "weighted avg       0.88      0.88      0.88       208\n",
      "\n",
      "Accuracy: 0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "# 捕获警告的函数\n",
    "def catch_xgboost_warnings():\n",
    "    # 配置警告过滤器\n",
    "    warnings.simplefilter(\"always\")  # 捕捉所有警告\n",
    "    with warnings.catch_warnings(record=True) as caught_warnings:\n",
    "        try:\n",
    "            # 训练 XGBoost 模型\n",
    "            xgb_model.tune_and_train(xgb_param_grid)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred: {e}\")\n",
    "        \n",
    "        # 检查是否捕获到特定警告\n",
    "        for warning in caught_warnings:\n",
    "            if \"A worker stopped while some jobs were given to the executor\" in str(warning.message):\n",
    "                print(f\"Caught Loky warning: {warning.message}\")\n",
    "            else:\n",
    "                print(f\"Other warning: {warning.message}\")\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, df, features, target, test_size=0.2, random_state=42):\n",
    "        self.df = df\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.X = self.df[features]  # 输入特征\n",
    "        self.y = self.df[target].astype(int)  # 目标变量\n",
    "        \n",
    "        # 划分训练集和测试集\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=self.test_size, random_state=self.random_state)\n",
    "        \n",
    "        # 标准化特征\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "    def train_and_evaluate(self, model, param_grid=None):\n",
    "        if param_grid:\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "            grid_search.fit(self.X_train_scaled, self.y_train)\n",
    "            print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "            best_model = grid_search.best_estimator_\n",
    "        else:\n",
    "            model.fit(self.X_train_scaled, self.y_train)\n",
    "            best_model = model\n",
    "\n",
    "        # 预测和评估\n",
    "        y_pred = best_model.predict(self.X_test_scaled)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        print(\"Accuracy:\", accuracy_score(self.y_test, y_pred))\n",
    "\n",
    "    def oversample(self):\n",
    "        smote = SMOTE(random_state=self.random_state)\n",
    "        self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train_scaled, self.y_train)\n",
    "        return self.X_train_resampled, self.y_train_resampled\n",
    "\n",
    "class LogisticRegressionModel(ModelTrainer):\n",
    "    def __init__(self, df, features, target, test_size=0.2, random_state=42):\n",
    "        super().__init__(df, features, target, test_size, random_state)\n",
    "        self.model = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
    "\n",
    "    def tune_and_train(self, param_grid):\n",
    "        self.train_and_evaluate(self.model, param_grid)\n",
    "\n",
    "class KNNModel(ModelTrainer):\n",
    "    def __init__(self, df, features, target, test_size=0.2, random_state=42):\n",
    "        super().__init__(df, features, target, test_size, random_state)\n",
    "        self.model = KNeighborsClassifier()\n",
    "\n",
    "    def tune_and_train(self, param_grid):\n",
    "        self.train_and_evaluate(self.model, param_grid)\n",
    "\n",
    "class XGBoostModel(ModelTrainer):\n",
    "    def __init__(self, df, features, target, test_size=0.2, random_state=42):\n",
    "        super().__init__(df, features, target, test_size, random_state)\n",
    "        self.model = xgb.XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "    def tune_and_train(self, param_grid):\n",
    "        self.train_and_evaluate(self.model, param_grid)\n",
    "\n",
    "# 使用该类\n",
    "df = pd.read_excel('data.xlsx')\n",
    "bins = [0, 50, 100, 150, 200,300,500]\n",
    "labels = ['0','1','2','3','4','5']\n",
    "df['aqi_rank'] = pd.cut(df['aqi'], bins=bins, labels=labels, right=True)\n",
    "df['pbtime'] = pd.to_datetime(df['pubtime'])\n",
    "df.set_index('pubtime', inplace=True)\n",
    "\n",
    "features = ['so2_24h', 'no2_24h', 'co_24h', 'o3_24h', 'pm2_5_24h', 'pm10_24h']\n",
    "target = 'aqi_rank'\n",
    "\n",
    "\n",
    "# 逻辑回归\n",
    "log_reg_model = LogisticRegressionModel(df, features, target)\n",
    "log_reg_param_grid = [\n",
    "    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'solver': ['liblinear']},\n",
    "    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'solver': ['lbfgs']},\n",
    "    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['elasticnet'], 'solver': ['saga'], 'l1_ratio': [0.5]}\n",
    "]\n",
    "log_reg_model.tune_and_train(log_reg_param_grid)\n",
    "\n",
    "# KNN\n",
    "knn_model = KNNModel(df, features, target)\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "knn_model.tune_and_train(knn_param_grid)\n",
    "\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBoostModel(df, features, target)\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "catch_xgboost_warnings()\n",
    "xgb_model.tune_and_train(xgb_param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d55e60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09037b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa961a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b620ca62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73f1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9255d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9203b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
